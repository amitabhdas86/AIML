{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitabhdas86/AIML/blob/master/RNN_Shakespear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "t9k5heqzZ6CP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "metadata": {
        "id": "eiVWTdIJZ6CQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The objective of this experiment is to understand RNN."
      ]
    },
    {
      "metadata": {
        "id": "dkHMFuSpZ6CS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this experiment we will use RNN to classify text one character at a time. We will be using shakespeare.txt as our input file to the classifier."
      ]
    },
    {
      "metadata": {
        "id": "LOs7dwuIZ6CT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The idea behind RNNs is to make use of sequential information. In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks thatâ€™s a very bad idea. If you want to predict the next word in a sentence you better know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being depended on the previous computations."
      ]
    },
    {
      "metadata": {
        "id": "jyLHK63HZ6CU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Keywords\n",
        "\n",
        "* RNN\n",
        "* Gated recurrent unit\n",
        "* Crossentropy\n",
        "* Adam"
      ]
    },
    {
      "metadata": {
        "id": "zvo0Q5wAZ6CW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Expected time to complete the experiment is : 90 min"
      ]
    },
    {
      "metadata": {
        "id": "sSPf03mmswF6",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "9ff50dad-3651-4427-9326-441a5bfb872c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Experiment Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n",
        "  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/week_12/module_3_week_12_experiment_1.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video width=\"800\" height=\"300\" controls>\n",
              "  <source src=\"https://cdn.talentsprint.com/talentsprint/archives/sc/aiml/aiml_2018_blr_b6/cfus/week_12/module_3_week_12_experiment_1.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "Mai03dwIgRGG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Steps"
      ]
    },
    {
      "metadata": {
        "id": "On6MHAPdgXn8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"P19A06E_test\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoPyleSigYRH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"981234567\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7POOx3PlJwS_",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "8c6f92b0-0faa-4661-dd23-249364e54721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook=\"BLR_M3W12_SAT_EXP_1\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx pip3 install torch\")\n",
        "    ipython.magic(\"sx wget https://cdn.talentsprint.com/aiml/Experiment_related_data/week10/Exp1/shakespeare.txt\")\n",
        "    ipython.magic(\"sx pip3 install unidecode\")\n",
        "    print (\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    \n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getComplexity() and getAdditional() and getConcepts():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n",
        "\n",
        "      r = requests.post(url, data = data)\n",
        "      print(\"Your submission is successful.\")\n",
        "      print(\"Ref Id:\", submission_id)\n",
        "      print(\"Date of submission: \", datetime.datetime.now().date().strftime(\"%d %b %Y\"))\n",
        "      print(\"Time of submission: \", datetime.datetime.now().time().strftime(\"%H:%M:%S\"))\n",
        "      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n",
        "      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "      return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if Additional: return Additional      \n",
        "    else: raise NameError('')\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "  \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup completed successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MaCOXOdNpiKr",
        "colab_type": "code",
        "outputId": "26b7cea6-12f8-4c0a-ec36-37f054df7d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!wc -l *.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39999 shakespeare.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T3HMm0p-Z6CX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Preparing the data"
      ]
    },
    {
      "metadata": {
        "id": "-6o_k37DZ6CY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the unidecode package."
      ]
    },
    {
      "metadata": {
        "id": "11e72PpPZ6Ca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Importing required packages\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sE5njLNJZ6Cg",
        "colab_type": "code",
        "outputId": "d8727f93-f7b5-4a15-a97d-f0f8c823e049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "## code to find length of all_characters and storing the value in n_characters\n",
        "n_characters = len(all_characters)\n",
        "## code to convert unicode characters into plain ASCII.\n",
        "file = unidecode.unidecode(open('shakespeare.txt').read())\n",
        "## code to find length of the file\n",
        "file_len = len(file)\n",
        "## printing the length of the file\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 1115393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gM3NTD74Z6Cp",
        "colab_type": "code",
        "outputId": "233b1477-0815-4b5c-aae1-12a97d988d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "file[:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "1BfQ1VWCZ6Cw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As the string is large, we are going to split it into chunks to provide inputs to the RNN using function random_chunk()."
      ]
    },
    {
      "metadata": {
        "id": "1TffxtFCZ6Cz",
        "colab_type": "code",
        "outputId": "21cf24b5-fe13-4ca3-a97f-23a196473222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "## Initializing the length of chunk\n",
        "chunk_len = 200\n",
        "## Function to split the string into chunks\n",
        "def random_chunk():\n",
        "    ## Initializing the starting index value of the big string \n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    ## Initializing the ending index of the string \n",
        "    end_index = start_index + chunk_len + 1\n",
        "    ## returning the chunk\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "\n",
            "LEONTES:\n",
            "Well said, Hermione.\n",
            "\n",
            "HERMIONE:\n",
            "To tell, he longs to see his son, were strong:\n",
            "But let him say so then, and let him go;\n",
            "But let him swear so, and he shall not stay,\n",
            "We'll thwack him hence w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RyKv4jyAZ6C6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  2. Building the model"
      ]
    },
    {
      "metadata": {
        "id": "Biz0cKYkZ6C8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model will take as input the character for step $(t-1)$, and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
      ]
    },
    {
      "metadata": {
        "id": "3h1GIrjHZ6C9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###importing required packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "### Creating recurrent neural network\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kP3H8LiSZ6DC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Defining the helper functions"
      ]
    },
    {
      "metadata": {
        "id": "cpWdV9iEZ6DD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Inputs and targets"
      ]
    },
    {
      "metadata": {
        "id": "kGrkkrg5Z6DF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each chunk will be turned into a tensor, specifically a LongTensor (used for integer values), by looping through the characters of the string and looking up the index of each character in all_characters."
      ]
    },
    {
      "metadata": {
        "id": "_j2hxN7QZ6DF",
        "colab_type": "code",
        "outputId": "ffc66d95-7351-4af5-e55c-fd0756f7d916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    ## tensor is a array\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TrottX4SZ6DL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters up to the last, and the target will be all characters from the first. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
      ]
    },
    {
      "metadata": {
        "id": "siN-Z8X_Z6DN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4QPs5BqZ6DS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Evaluating"
      ]
    },
    {
      "metadata": {
        "id": "MgEPSdSIZ6DU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "v2m-JfwXZ6DW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = decoder.init_hidden()\n",
        "    prime_input = char_tensor(prime_str)\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "        \n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZVmbuZ4Z6De",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Training the model"
      ]
    },
    {
      "metadata": {
        "id": "vEbpHyx0Z6Dg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To keep track of how long training takes, we have added a time_since(timestamp) function which returns a human readable string"
      ]
    },
    {
      "metadata": {
        "id": "rFevLn43Z6Dh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Importing required packages\n",
        "import time, math\n",
        "## function to print amount of time passed\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QXqylIRyZ6Dn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The main training function"
      ]
    },
    {
      "metadata": {
        "id": "n3vWoTsxZ6Dp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden()\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = decoder(inp[c], hidden)\n",
        "        loss += criterion(output, target[c].unsqueeze(dim=0))\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dB-y61RZZ6Dt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we define the training parameters, instantiate the model, and start training"
      ]
    },
    {
      "metadata": {
        "id": "OPG6aUEeZ6Du",
        "colab_type": "code",
        "outputId": "d1eae725-c3da-4853-cfe9-3142099a4b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4043
        }
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 2000 #Number of epochs\n",
        "print_every = 50\n",
        "plot_every = 20\n",
        "hidden_size = 100\n",
        "n_layers = 1\n",
        "lr = 0.005\n",
        "\n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "## Optimizer\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "## Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "#In this for loop for every 100th iteration we are printing the time taken, loss and the chunk.\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0m 6s (50 2%) 2.3369]\n",
            "Wh'is angyand\n",
            "A\n",
            "Ane thand okises ghise foce ? eanr'lllltir saess\n",
            "Oof iss\n",
            "Yilles,\n",
            "\n",
            "OORQLOE:\n",
            "Wout theit  \n",
            "\n",
            "[0m 12s (100 5%) 2.3522]\n",
            "Whaven, bee weve houn ill me thee mer thith, theens rleatr bus, os what weand taris mely and to theerv \n",
            "\n",
            "[0m 19s (150 7%) 2.0388]\n",
            "Whime I cacgth me\n",
            "Thoun ind move thou ir to pard thier but youncy the you none thiceam noth the in my  \n",
            "\n",
            "[0m 25s (200 10%) 2.1047]\n",
            "Whed roth\n",
            "Poud wood loter sole fill came with mant prarepsest mompheest bome mustell ment thou thou th \n",
            "\n",
            "[0m 31s (250 12%) 2.1258]\n",
            "Who in it hey of the will monge kove nours youtring with heer: fo and ain and thou dowl, stas and it I \n",
            "\n",
            "[0m 37s (300 15%) 2.2256]\n",
            "When the goxden,\n",
            "By hirst habugh, the laitese;\n",
            "No the proventse gods me hen thatinging als him hive, c \n",
            "\n",
            "[0m 43s (350 17%) 1.9526]\n",
            "Where of his fastere, well make the with wits this call to thee grate as rune!\n",
            "\n",
            "CENEN:\n",
            "\n",
            "CRUIS:\n",
            "Whe bri \n",
            "\n",
            "[0m 49s (400 20%) 1.8891]\n",
            "Which mall saise mould men, who hadus sailess bucon,\n",
            "Of shall intselle,\n",
            "That show that st hebut hath s \n",
            "\n",
            "[0m 56s (450 22%) 2.1180]\n",
            "Wheard, scordir see: a slimieled, seer whose there chatair,\n",
            "I they stay but then there hower that ford \n",
            "\n",
            "[1m 2s (500 25%) 2.0348]\n",
            "Where prace leake and and as lis in and day,\n",
            "Sand cat lithe;\n",
            "And here shall so mors toughture a saynet \n",
            "\n",
            "[1m 8s (550 27%) 2.0098]\n",
            "Whery to thim. I which me of home I him, come the what the servis with your,\n",
            "The con doaning Hise your \n",
            "\n",
            "[1m 15s (600 30%) 2.2329]\n",
            "WhORKES:\n",
            "Wenther nesso, hadonce's thour mook not you have even the sa exemy, there.\n",
            "\n",
            "ISABELLA:\n",
            "Blownci \n",
            "\n",
            "[1m 21s (650 32%) 2.1988]\n",
            "When,\n",
            "Stall\n",
            "for you have see am elloughterance of me.\n",
            "\n",
            "HARWINIA:\n",
            "Promm shen I dam beich the prook beef \n",
            "\n",
            "[1m 27s (700 35%) 1.9901]\n",
            "Whis deapdines, the strestandy know of the my fright, whrturning, died, have is rechirs, had what my s \n",
            "\n",
            "[1m 33s (750 37%) 1.8036]\n",
            "WhRessen: consed me; Your him changelf\n",
            "He must all in.\n",
            "\n",
            "LEOMEN:\n",
            "\n",
            "Sich make 'take unor slair; Come ell, \n",
            "\n",
            "[1m 40s (800 40%) 1.7810]\n",
            "What py her\n",
            "As ith, that sarus, the gain are a more amur you when her thus unare bathe a call pourds s \n",
            "\n",
            "[1m 46s (850 42%) 1.8551]\n",
            "Wheres have a mout, une diserve's fair do son fith and and First: and for a I ditse amp't:\n",
            "We'll anbas \n",
            "\n",
            "[1m 52s (900 45%) 1.8871]\n",
            "What who her the pear, sing would the pugst bety hadg.\n",
            "\n",
            "HARTER:\n",
            "Not but thoud he well him thou and wer \n",
            "\n",
            "[1m 59s (950 47%) 2.0676]\n",
            "What for you.\n",
            "\n",
            "JULIET:\n",
            "Ind more encoge, my me lord; les' fare:\n",
            "My lord, City for of and trome monter'd \n",
            "\n",
            "[2m 5s (1000 50%) 1.8394]\n",
            "What may heaveried,\n",
            "low? I with I is that affle anture.\n",
            "\n",
            "LADY EDWARWICK:\n",
            "Be nawy me thun our sese\n",
            "Ruid \n",
            "\n",
            "[2m 11s (1050 52%) 2.0279]\n",
            "Wheer:\n",
            "I lo, we have would yould the me to the crick you\n",
            "Leps of thuse to man as with deed it for but  \n",
            "\n",
            "[2m 18s (1100 55%) 1.8137]\n",
            "When like make no lith sir, from what foult; the my desserven to beat and fierage,\n",
            "And, thy say do wou \n",
            "\n",
            "[2m 24s (1150 57%) 2.0218]\n",
            "When causters if hind too love allanger what I for quess of thatted hands, fathoughtelvest,\n",
            "You subjec \n",
            "\n",
            "[2m 30s (1200 60%) 1.5209]\n",
            "What take chour's ellous.\n",
            " ram in repains one the what had, thy he would we stich my fring-\n",
            "Nuring lif \n",
            "\n",
            "[2m 37s (1250 62%) 1.7937]\n",
            "Whone our uposs strunst sir?\n",
            "\n",
            "QUEENES:\n",
            "How he who hough of Mards hath of gought in lords give the como \n",
            "\n",
            "[2m 43s (1300 65%) 1.9282]\n",
            "Which to be his postiond,\n",
            "So fighs bose not when heireling or Warwick?\n",
            "\n",
            "GONZAULIO:\n",
            "Whick with thes swe \n",
            "\n",
            "[2m 50s (1350 67%) 1.7226]\n",
            "What the prate:\n",
            "For have now, and hown trage the oncle our say orn and:\n",
            "Not of this onour'd dear in en \n",
            "\n",
            "[2m 56s (1400 70%) 1.7981]\n",
            "Whech doft here\n",
            "And thim many be I prope the what more be sure and and,\n",
            "Have soul me be to comulf his  \n",
            "\n",
            "[3m 3s (1450 72%) 1.8352]\n",
            "Whan I straved that herier he desty?\n",
            "\n",
            "LADY CLAUMERS:\n",
            "I farentystatast to he preitiopen you wither, the \n",
            "\n",
            "[3m 9s (1500 75%) 1.7240]\n",
            "Whoo to good counten March himord?\n",
            "\n",
            "SAPTIS:\n",
            "No who way work of I dows, do wareter one unto.\n",
            "\n",
            "ROMES:\n",
            "An \n",
            "\n",
            "[3m 15s (1550 77%) 1.6281]\n",
            "What thou duke that it appore, dof\n",
            "I kam well king,\n",
            "To read lown with so mare reath.\n",
            "\n",
            "KING EOK:\n",
            "And ma \n",
            "\n",
            "[3m 22s (1600 80%) 1.7980]\n",
            "Whis to thee'le pray,\n",
            "The houdis not tell in but\n",
            "Art him brasing are in beant before, Fie: I my parth  \n",
            "\n",
            "[3m 28s (1650 82%) 1.8235]\n",
            "Whehe,\n",
            "To for repon to shours, thy muptining to me the dounes of my so whow your glood is till herais  \n",
            "\n",
            "[3m 34s (1700 85%) 1.8421]\n",
            "Why;\n",
            "I should is foul me overer, by setor ause the priaibour,\n",
            "Will the restrese as his be him your,\n",
            "Wh \n",
            "\n",
            "[3m 41s (1750 87%) 2.0100]\n",
            "Wherel hand you\n",
            "Was her grace me and kssury so father.\n",
            "\n",
            "BADINA:\n",
            "A may again and his must then?\n",
            "What to \n",
            "\n",
            "[3m 47s (1800 90%) 2.0909]\n",
            "Whis,\n",
            "And hering he have and he well say.\n",
            "\n",
            "AULIDIUS:\n",
            "And the his for thereft hand have houre,\n",
            "But look \n",
            "\n",
            "[3m 53s (1850 92%) 1.8093]\n",
            "Whiled too at this hey comed and my leance that with evisong: ston from, fathed:\n",
            "Which what I'll stan' \n",
            "\n",
            "[4m 0s (1900 95%) 1.8769]\n",
            "Who and the prooks,\n",
            "And this bret at my let both to shout your strant bleire.\n",
            "\n",
            "SICINIUS:\n",
            "That an to so \n",
            "\n",
            "[4m 6s (1950 97%) 1.8248]\n",
            "What is but Capcins? Nort, head.\n",
            "\n",
            "SESCESTERD MINCENTIO:\n",
            "Make that banas.\n",
            "\n",
            "ILA:\n",
            "By hir you he have the  \n",
            "\n",
            "[4m 12s (2000 100%) 1.8808]\n",
            "Where fet I sharked your, with shall hard,\n",
            "And sea, bod!\n",
            "\n",
            "GRvO:\n",
            "But tour his good Konericinands;\n",
            "I he' \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xWhQGN73Z6D4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Plotting the Training Losses"
      ]
    },
    {
      "metadata": {
        "id": "mkHYKnQiZ6D6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plotting the historical loss from all_losses shows the network learning"
      ]
    },
    {
      "metadata": {
        "id": "aRMgqaJoZ6D8",
        "colab_type": "code",
        "outputId": "22187438-4f82-454a-da19-62ee7f2242ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4XNW56P/vFGnUe3eT67LcewM3\nTIwNpjuUQAjBhCRwcvPLgeSGtEvCDZwDySUhJCGckBB6CRiMjRvFBfduWZaXbUmW1SzJ6lYfzfz+\nmK1BkiVZljWSrf1+nsfPM7P32nuvZUnzzuoWt9uNEEIIAWDt6wwIIYS4fEhQEEII4SVBQQghhJcE\nBSGEEF4SFIQQQnhJUBBCCOFl99WNlVJBwCtAPBAAPKm1Xt3i/CkgB2gyDt2jtc5TSj0HzALcwA+1\n1nt8lUchhBCt+SwoADcCe7XWzyilhgAbgdVt0izVWp9rfqOUmg+M1FrPVkqlAP8AZnf2kOLiqm5P\ntIiMDKKsrKa7l1+xzFhuM5YZzFluKXPXxMaGWto77rPmI631O1rrZ4y3g4DcLly2CPjQuD4diFRK\nhfkoi9jtNl/d+rJmxnKbscxgznJLmS/xXj12pw4opbYDA4Fl7Zx+USmVDHwJPA4kAPtanC82jlX6\nOJtCCCHohaCgtZ6jlJoEvK6Umqi1bm7u+RWwDijFUzu4vZ3L263etBQZGXRJUTI2NrTb117JzFhu\nM5YZzFluKXP3+bKjeSpQpLXO0VofVErZgVigCEBr/WqLtJ8A44F8PDWDZklAQWfPuZS2w9jYUIqL\nq7p9/ZXKjOU2Y5nBnOWWMnf9mvb4ckjqPOBRAKVUPBACnDXehyul1iul/I2084EjwAZguZFmCpCv\ntTbXT1cIIfqQL4PCi0CcUmorsAZ4BLhPKXWr1roC+ATYqZTahqfv4N9a6+3APqMf4nnjGiGEEL3E\ncqUvnX0pQ1LNWM0Ec5bbjGUGc5Zbytzla3p3SKoQQogrj89HH12u9uli/LPLGD8ksq+zIoQQlw3T\n1hRWbcvi7x+l9XU2hBDismLaoGC3WahvcPZ1NoQQ4rJi2qDgb7fR4HThusI72oUQoieZNyj4eWZB\nNzpdfZwTIYS4fJg3KNg9RW9obLpASiGEMA/zBgW/5qAgNQUhhGhm4qDgaT5qcEpNQQghmpk2KPjZ\npaYghBBtmTYoOKSmIIQQ5zFtUPB2NMvoIyGE8DJtUPAzNuaR0UdCCPEV0wYFh4w+EkKI85g2KMjo\nIyGEOJ9pg4KMPhJCiPOZNihITUEIIc5n2qDgMGoKjVJTEEIIL9MGBT+jplAvNQUhhPAybVDwlz4F\nIYQ4j8+241RKBQGvAPFAAPCk1np1i/MLgaeBJkADDwLzgPeA5i3RUrXWP/BF/hzepbOlpiCEEM18\nuUfzjcBerfUzSqkhwEZgdYvzLwELtda5Sqn3gCVADbBZa73ch/kCZPSREEK0x2dBQWv9Tou3g4Dc\nNkmmaq0rjdfFQDSeoNArmkcf1cuMZiGE8PJlTQEApdR2YCCwrOXx5oCglEoEFgO/BMYDY5RSq4Ao\n4Nda642+yFfzjGbZeU0IIb5icffCHsVKqUnAq8BErbW7xfE44BPgZ1rrDUqpAcDVwLvAMOALYITW\nuqGjezudTW67sY7RxXC73dz841WMGRrNfz1y9UVfL4QQVzhLewd92dE8FSjSWudorQ8qpexALFBk\nnA8D1gI/11pvANBa5wHNzU4ZSqkzwAAgq6PnlJV1v8XJ38/GuZoGiourun2PK1FsbKiU2STMWG4p\nc9evaY8vh6TOAx4FUErFAyHA2Rbnfw88p7Ve13xAKXWPUuox43UCnpFLeb7KoMPPJs1HQgjRgi/7\nFF4EXlZKbQUCgUeA+5RSFcB64D5gpFLqQSP9m8BbwJtKqZsBf+D7nTUdXSp/P5ssnS2EEC34cvRR\nLfCNTpI4Ojh+ow+y034G/GxUVdf31uOEEOKyZ9oZzQAOf5vsvCaEEC2YOyj42WhodNEbI7CEEOJK\nYPqg4HK7aXJJUBBCCDB7UPBv3qdZmpCEEAJMHhRkox0hhGjN1EGheaVUGZYqhBAe5g4Kzc1HMgJJ\nCCEAkwcFb/OR9CkIIQRg8qAgzUdCCNGauYOCNB8JIUQrpg4K/n7Nu69JTUEIIcDkQcHh51n6SYak\nCiGEh7mDgjQfCSFEK+YOCt7mIwkKQggBpg8KRvOR9CkIIQRg9qAgzUdCCNGKqYOCjD4SQojWTB0U\nvJPXpKYghBCA2YOCv6dPoVFqCkIIAZg8KDQ3H9VLTUEIIQCTBwVZ+0gIIVqz++rGSqkg4BUgHggA\nntRar25x/lrgKaAJ+ERr/aRx/DlgFuAGfqi13uOrPDYHhUapKQghBODbmsKNwF6t9XzgDuD/tTn/\nPHA7cBWwWCk1Rik1HxiptZ4NrDDS+IzNZsVmtUhNQQghDD6rKWit32nxdhCQ2/xGKTUMKNVa5xjv\nPwEWAbHAh8b16UqpSKVUmNa60lf59PezUS8zmoUQAvBhUGimlNoODASWtTicABS3eF8EDAdigH0t\njhcbaTsMCpGRQdjttm7nL9Bhw+V2Exsb2u17XInMVl4wZ5nBnOWWMnefz4OC1nqOUmoS8LpSaqLW\n2t1OMksHl3d03KusrKbbeYuNDcVmtVBb76S4uKrb97nSxMaGmqq8YM4ygznLLWXu+jXt8VmfglJq\nqlJqEIDW+iCeABRrnM7HUwNoNsA41vZ4ElDgqzyCp/lI+hSEEMLDlx3N84BHAZRS8UAIcBZAa30K\nCFNKJSul7HialjYY/5Yb10wB8rXWPg35/nabzGgWQgiDL5uPXgReVkptBQKBR4D7lFIVWuuVwPeB\nt4y072itjwPHlVL7jH4Il3GNT/nbrTQ6XbjcbqyWC7ZWCSFEv+bL0Ue1wDc6Ob8FmN3O8Z/6Kk/t\n8W+eq9Do8q6aKoQQZmXqGc3QYqVU2ZJTCCEkKPjbZfc1IYRoJkHBu3y21BSEEEKCgr15UTypKQgh\nhAQF6VMQQggvCQrSpyCEEF4SFKRPQQghvCQoSE1BCCG8JCjI7mtCCOElQcHbfCQ1BSGEMH1Q8LPL\n6CMhhGhm+qDgkD4FIYTwMn1QkNFHQgjxFdMHBT+pKQghhJfpg4JDRh8JIYSX6YOCdz8FGX0khBAS\nFJqbj+qlpiCEEBIUHN4F8aSmIIQQpg8KdpsVC9AoNQUhhJCgYLFY8POzUi81BSGEwO7LmyulngHm\nGs95Wmv9gXF8APBGi6TDgJ8C/sCTQIZxfKPW+re+zCN4NtqR0UdCCOHDoKCUWgiM01rPVkpFAweA\nDwC01nnAAiOdHdgErAKWA+9orR/zVb7a4/CzyugjIYTAt81HW4CvG6/LgWCllK2ddPcD72utz/kw\nL53yk5qCEEIAPqwpaK2bgGrj7QrgE+NYWw8Ci1u8n6+UWgf4AY9prQ909pzIyCDs9vZiTdfExoYS\nFOhHRXU9sbGh3b7PlcZMZW1mxjKDOcstZe4+n/YpACilbsYTFBa3c242cExrXWkc2gkUa63XGOde\nBcZ3dv+ysppu5y02NpTi4iqsFqhraKKwqBKrxdLt+10pmsttJmYsM5iz3FLmrl/THp+OPlJKXQf8\nHFiqta5oJ8ky4NPmN1rrY1rrNcbrHUBsB01OPSo8yB+3G87VNPr6UUIIcVnzWVBQSoUDzwLLtNal\nHSSbDhxqcc1PlFJ3G6/H4ak1+LyxPzLUAUBZVb2vHyWEEJc1XzYf3QnEAO8qpZqPfQ6kaq1XGu8T\ngaIW17wJvKaU+p6RtxU+zJ9XVFgAAKWVdQxJMF9bpBBCNPNlR/NLwEsXSDO+zftcYKGv8tSR5ppC\nqdQUhBAmZ/oZzSDNR0II0UyCAhAV1lxTqOvjnAghRN+SoABEhDiwAGWVUlMQQpibBAU8K6WGBftL\n85EQwvQkKBgiQx2UVtXjdrv7OitCCNFnJCgYosICcDa5qKqVCWxCCPO66KCglHIopQb5IjN9yTsC\nSfoVhBAm1qV5Ckqpx4FzwMvAXqBKKbVBa/1LX2auN0W1GJYqE9iEEGbV1ZrCjcALeJbC/lhrPRO4\nyme56gNfTWCTYalCCPPqalBo1Fq7gaXAh8Yxny9U15ual7qQEUhCCDPr6jIX5UqpNcBArfUOpdQy\noF9tVeatKUifghDCxLoaFL4BfA3YZryvA77lkxz1kYiQ5j4FaT4SQphXV5uPYvEsY12slPoOcDcQ\n7Lts9T4/u5WwID9ZFE8IYWpdDQr/BBqUUpPxbJ/5PvC8z3LVRyLDAiiTCWxCCBPralBwa633ALcC\nL2itPwH63b6VUaEOGp0uquucfZ0VIYToE10NCiFKqenAcmCdUsoBRPouW33jq85m6VcQQphTV4PC\n74H/Af6mtS4GnsCzS1q/IpvtCCHMrkujj7TW7wDvKKWilFKRwM+MeQv9isxVEEKYXZdqCkqpq5RS\nGcAx4ASQrpSa5tOc9YEoaT4SQphcV5uPngZu1lrHaa1j8AxJ/X++y1bfkG05hRBm19XJa01a6yPN\nb7TWB5RSFxyio5R6BphrPOdprfUHLc6dAnKAJuPQPVrrPKXUc8AswA380Bj11CskKAghzK6rQcGl\nlLod2Gi8X8JXH+btUkotBMZprWcrpaKBA8AHbZIt1Vqfa3HNfGCkcU0K8A9gdhfzeMn87DZCZQKb\nEMLEutp89D3gO8ApIAvPEhffvcA1W/CsqgpQDgQrpS60iN4ijAX3tNbpQKRSKqyLeewRkaEOyirr\nZAKbEMKUOq0pKKW24mnGAc9ktTTjdRjwCjCvo2u11k1AtfF2BfCJcaylF5VSycCXwONAArCvxfli\n41hlR8+JjAzCbu/+gq2xsa33TkiKDeF04TlcNhsJ0f1qJY9W2pbbDMxYZjBnuaXM3Xeh5qNfXOoD\nlFI34wkKi9uc+hWwDijFUzu4vZ3LLzhruqysptt5i40Npbi4qtWxlMER7DxyhjVbM7jpqqHdvvfl\nrL1y93dmLDOYs9xS5q5f055Og4LWevNFPaUNpdR1wM+BJVrrijb3frVFuk+A8UA+nppBsySg4FLy\ncLGmqTje2HCc7UfOcOOcZCyWfreahxBCdOii92juKqVUOPAssExrXdr2nFJqvVLK3zg0HzgCbMCz\nlAZKqSlAvta6V0N+oMPOFBVLUVktGfkdtloJIUS/1NXRR91xJxADvKuUaj72OZCqtV5p1A52KqVq\n8YxM+rfW2q2U2qeU2o5nE59HfJi/Ds0Zl8DOtEK2pxYwYkB4X2RBCCH6hM+Cgtb6JeClTs7/Efhj\nO8d/6qs8ddWYIVFEhPizO72Iu68did8ldGQLIcSVxGfNR1cyq9XC7LEJ1NQ7OXSypK+zI4QQvUaC\nQgfmjPP0d29L7dV+biGE6FMSFDowIDaEIQmhpGaWUlXT0NfZEUKIXiFBoRNTRsXicrvRp8v7OitC\nCNErJCh0Qg2KAEDnSFAQQpiDBIVODE0Mw89u5bgEBSGESUhQ6ISf3crwpDByi85RXdfY19kRQgif\nk6BwAaMGReAGqS0IIUxBgsIFqMGRgAQFIYQ5SFC4gGFJYdisFhmBJIQwBQkKF+DwszE0KYzswipq\n6y+4A6kQQlzRJCh0gRoUgdsNJ/MqLpxYCCGuYBIUusA7X0GakIQQ/ZwEhS4YPiAcq8Uinc1CiH5P\ngkIXBDrsDEkIJaugEn26jPrGtltNCyFE/+DLTXb6lTHJkWQVVPLfbx7AarEwJCGE/7htApGhjr7O\nmhBC9BgJCl1045xkBsaGkFVQybHsMrIKqth1tJAlMwf3ddaEEKLHSPNRF/n72Zg5Jp67Fo3kR3dO\nAiA1UzbgEUL0LxIUuiE82J+hiaEczymXuQtCiH5FgkI3jR8WTZPLzdFTpX2dFSGE6DE+7VNQSj0D\nzDWe87TW+oMW5xYCTwNNgAYeBOYB7wFpRrJUrfUPfJnH7powPIZV205xOKOEqSqur7MjhBA9wmdB\nwfjQH6e1nq2UigYOAB+0SPISsFBrnauUeg9YAtQAm7XWy32Vr56SnBhKaJAfhzNLcLvdWCyWvs6S\nEEJcMl82H20Bvm68LgeClVK2Fuenaq1zjdfFQLQP89LjrBYL44ZGU3GugZyic32dHSGE6BEWt9vt\n84copR4C5mqtv9nOuURgKzATGA/8BTgJRAG/1lpv7OzeTmeT2263dZbEZ7YcyOXZ1/dx79LR3Hmt\n6pM8CCFEN7XbvOHzeQpKqZuBFcDids7FAR8DD2utS5RSJ4BfA+8Cw4AvlFIjtNYNHd2/rKym23mL\njQ2luLiq29cPjgnCYoGdhwu4ZmJSt+/T2y613FciM5YZzFluKXPXr2mPrzuarwN+DizRWle0ORcG\nrAV+rrXeAKC1zgPeMZJkKKXOAAOALF/ms7uCA/wYMSCck3kVnKttJCTQr6+zJIQQl8RnfQpKqXDg\nWWCZ1rq9cZu/B57TWq9rcc09SqnHjNcJQDyQ56s89oQJw6NxuyE1QyayCSGufL6sKdwJxADvKuVt\nb/8cSAXWA/cBI5VSDxrn3gTeAt40mpz8ge931nR0OZgyKpb3N2ey51gRs8cldOmagyfOkhAdREJU\nkI9zJ4QQF8dnQUFr/RKeYacd6WgluRt9kB2fSYwOZlBcCKmZJVTXNRIc0HkT0u70Ql78KA2Hn40H\nl41hqortpZwKIcSFyYzmHjAjJY4ml5v9x4s7TVdxrp7X1mv87Z7/9j+vTOXjbVn0xggwIYToCgkK\nPWBGSjwAu9OLOkzjdrv51zpNdZ2T5QuG8/i9U4gOc7ByaxZvf3ayt7IqhBCdkqDQA2IjAhmaGEb6\nqTIqa9rvAtl+5AwHT55l9OAIrpk6kMHxofzyW9OJjwzks325FF3C0FohhOgpsp9CD5mZEkdWQSX7\ndDELJw/gRG45r67TVNY04HK5qa1vIsDfxgPXp2A1lsQIC/bnlrnD+NuqND7efooVN4zp41IIIcxO\nago9ZNpoz6J4u48Wsju9kGffOkhBSQ0hgX5EhDoYHB/CQzeOJSYisNV100fHkRQTzI4jhRRKbUEI\n0cekptBDosICGDUwHJ1Tjs4pJ8DfxsPLxzNuaOdLOlmtFm66KpkXP0pjtdQWhBB9TGoKPWjGGE+H\nc2Sog8fvnXrBgNBsmpLaghDi8iBBoQfNm5jE/UtH84v7pjEoLqTL1zXXFlxuNx99ef6KHgdPnOWL\nA5f1xG4hRD8hzUc9yG6zMq+bC+NNGx3H4J3Z7EwrZNaYBCYM99QyTp2p5M8rU2lyubHbLMydcOUs\nvCeEuPJITeEyYbVYeOD6FGxWC/9cm8652kbqG5t4adVRmlxuHP42Xt9wXPZuEEL4lASFy8jg+FBu\nvnooFecaeHPjcd75/CRnSmv42rRBPLRsDI1OF39ZmUptvbOvsyqE6KckKFxmls4azLCkMHYeLWTT\ngTwGxgazfMEwJo+KZcmMwRSW1fKPNek4m1x9nVUhRD8kQeEyY7NaWXFDCn52K3ablYduHIufsbPc\nbfOHMXJgOPuOF/N/X91LQUl1H+dWCNHfSFC4DCVGB/Oze6fy+L1TGNhiFJPdZuVHd0xk7oREThee\n49ev7GHLofw+zKkQor+RoHCZGpIQytDEsPOOB/jb+fb1KTx8yzjsViuvrD3G3mMdL8QHUN/Q5Kts\nCiH6GQkKV6hpo+N4/JtT8bd7AsPZitp2032wJYP/+MMWDlxgWW8hhAAJCle0ATHBfONro6ipd/LS\nx0dpcrXufF67K5vV27Npcrl589MTNDRKjUEI0TkJCle4uRMSmT46jpO5FazckkVdg2e46pZD+bz3\nRQaRoQ7mjEugpLKO9btP93FuhRCXO5nRfIWzWCx8a4kiM7+ST3Zm88nObAIdNurqmwgJ9OOxuyYR\nEeLgSGYJa3Zmc/WEJGJjQ/s620KIy5TUFPqBoAA/fnTHROZNTGTc0CiiwgIYFBfCj+6YSGJ0MIEO\nO7fNH05Do4t/b8ro6+wKIS5jPq0pKKWeAeYaz3laa/1Bi3PXAk8BTcAnWusnjePPAbMAN/BDrfUe\nX+axv0iKCeb+pSkdnr96fCKf789lR9oZjp8uIzKw/R999pkq/rYqjfmTkrhuxmBfZVcIcZnyWU1B\nKbUQGKe1ng0sAf7QJsnzwO3AVcBipdQYpdR8YKRxzQojjegBVquFuxeNBODN9cfaTZORV8Ezbx3g\nTGkNK7dkUnGuvjezKIS4DPiy+WgL8HXjdTkQrJSyASilhgGlWuscrbUL+ARYZPz7EEBrnQ5EKqXO\nH6wvukUNjkQNimDfsSJOnalsdU6fLuN37xykvqGJqSqWBqeLNTuzO7yX2+32dXaFEH3AZ0FBa92k\ntW5eh2EFniai5jGRCUDLgfNFQGI7x4uNY6KHLLsqGYCPt53yHjuZW8Fz7x7C6XTx/VvG8d2bxhIT\nHsCmA3mUVtadd4/6xiae/Nde/vjeoU6f5Wxyca62sSezL4TwMZ+PPlJK3YwnKCzuJJnlIo97RUYG\nYTfWBuoOs43EmR8Twurt2Rw4cZZqpxuHn40XVqbidLn5+bdnMGOMJwbfs2Q0f3znIJ8dyOfh5RNb\n3eOF9w5y6kwVAG6bjbiooPOec/pMJU//ay9llXX8+SfXEB0eeF6a3ma2n3UzM5Zbytx9vu5ovg74\nObBEa13R4lQ+rWsAA4xjDW2OJwEFnT2j7BK2r4yNDaW4uKrb11+p7vzaKH7z8i7+Z+VhCstqqaxu\n4L4liqGxwd7/j3FDIoiPDGTDrmwWTEwkNsLzob47vZD1O7Pxt1tpcLrYuCOLxW06pHenF/LPT45R\nb0yWe2+j5vb5w3u3kG2Y9WdtxnJLmbt+TXt82dEcDjwLLNNal7Y8p7U+BYQppZKVUnZgGbDB+Lfc\nuH4KkK+1NtdPtxdMS4lncFwIhzNKKCytYenMwSyYNKBVGpvVys1XD6XJ5eYP7x1i454cMvMr+de6\nYzj8bPznnZOwWGBvm+Uz1uw4xYsfpYEFHlyWQmiQH5sO5HW4/pKzyUX2mSpcfdBHUVpZR0ZexYUT\nCmEivqwp3AnEAO8qpZqPfQ6kaq1XAt8H3jKOv6O1Pg4cV0rtU0ptB1zAIz7Mn2lZLBZuvnoof/og\nlWkqltsXtP8tfkZKPGlZpexIK+Stz054j6+4IYVRgyJQgyI4drqcsqp6IkMdlFXV89GXp4gMdfDY\nXZNIjA6mqKyWVdtO8WVqAYumDmx1/5O5Ffxr/THyiqsZkhDKHQuGk5IcBUBZVT35Z6sZlhRGoMM3\nv6Z/+fAIWQWV/PY7s0hopwlMCDOyXOmjSIqLq7pdADNWM+GrcheV1RATEYjV0nnXTWV1AzuPFrI7\nvZDhSeHctWgEFouFz/bl8sbG49zztVEsmjqQNzce59N9udy/dLR3r+rK6gYe+8t2okIdPPXQLKxW\nCzV1jfx7UwabDnqW/R4+IIyMvErv68rqBorLPR3cwQF2Fk0dyLXTBhES6HfJZW526kwlv3llLwDz\nJiZx/9LR3b53Rxoam/jLh0eYmRLP7HF9M17CjL/jUuYuX9PuH74sc2FicZFd+3YcFuzP4umDWDx9\nUKvjU0bF8sbG4+zTRUwZFcumg/nEhAcwp8UHYFiwP3PGxbPlUAEHT57FYoFX12sqzjUwICaYby0Z\nzYiB4WQVVPLvTRmkZ5cR5LAzcXg0sZGB7EwrZNW2U6zfncOKG1KYNjquR8q+6YAnIPn7Wdl+pIBb\n5w4lPMTRI/dudjijhMMZJZwprWHW2HgsFwi+QlwOJCiIbosMdTBiQDg6p5x3vziJs8nFDbOHYLe1\n7qpaPH0wWw4V8PKadGrrndhtFm6dO5Sls75KOzQxjMfumkRlTSOhQX7e2svt84az+VA+K7dm8vKa\ndJJigkmKCb6kfNfUOdl59AzRYQFcP2swr204zsa9uSzvoBmtu3Yb+1wUldVyuvAcQxLMNyJGXHkk\nKIhLMk3FcjKvgl1HC4kOc3DV+MTz0iTFBDNheDSHM0oYlhTGt69PYUA7H+wWi4XwYP9Wxxz+NhZP\nH0RkqIO/fniEv354hF/cNw2Hv42sgkre/uwEtfVNRIY6iAz1Z/bYBNTgyE7zvCPtDA2NLhbMSeLq\nCYl89GUWXxzI44bZQzrtvygqr+XDrZlU1TTSaIysumexYlCL3fGa1Tc0cTjjLDarhSaXm93phRIU\nxBVBFsQTl2SKivW+vmF28nm1hGYrbkjhB7eP52f3Tm03IFzI9NFxLJoykLyz1by6XvPBlkx+++o+\nTuRWcLailtTMErYcKmh3X4mW3G43mw7mYbNauHpCEn52G9dOG0RtvZPNB/M5V9vI4Yyz7D9e3GpE\nVKPTxV8+SGVnWiFpWaUcz63geG4F735xst3nHM4soaHRxbXTBhLgb2N3etFFzwI/W17LyVwZHSV6\nl9QUxCWJCQ9kTHIkZVX1XD3h/FpCs9AgfyaPjO3wfFfccc0IMvIr2JF2BoDosAAeuH40KclR1NY7\neefzk2w5lM/+42eZ3kHfw4ncCvKKq5k+Os5bK1k4ZQBrdmbz/uaMVh/yV49P5P7rR2O1WFi5JZPT\nReeYOyGRexePwm6z8ru3D5KWVcrJ3ApGDAxv9Zw9RtPRnHGJVFY3sCOtkMz8SoYPaJ2uMy+uSiMz\nv5L7rlMsmPzVkOFtqQUcyy7j7mtHERQgf8KiZ0lNQVyyH90xkSe+PaPDWkJP8bNb+f4t4xgYG8yC\nSUn8ZsUM7xDWQIed62Z4OsI/3ZvT7vV1DU5WbcsCYGGLD9ngAD+WzR5CgL+NlCGR3DgnmeSEUL5M\nLeCVtcdIyypl3e7TxEcGcve1I/Gz27zDegE++jKz1XPqG5o4fPIs8VFBDIwNZkZKPAC70zvfS7ul\n0so6MvM9I7JeXa/5fH8ujc4mXlmbzstr0tl25Az/XJsua1CJHidfM8Qls1mt+DgeeMVGBPKbFTPb\nPZcYHcz4YdGkZpaQfaaqVRt+Vn4FT72ylzOlNahBEajBEa2uvWF2MjfMTva+XzxjEL97+yBfHi5g\nx5Ez2KwWHrppLAH+X/3JjBoUwZjkSNJOlXEit5yRAz33PJRxlgani+mjY7FYLIwdGkVwgJ09xwq5\nc9GICw4BBjh48izgqcXsO1b1VGLEAAAUPElEQVTE6xuOs2F3DkXltQyOD8HfbmOfLubTvbl8rc2o\nMCEuhdQURL9y7TTPBLnm2oLb7eazfbk8+sctnCmtYfH0QTx616QLDg8NDvDsWjckIZQml5tb5g5l\naOL5C/Z+VVvI8h7bazQdTR/tqSHYbVYmj4ql/FwDJ3LKu1SOAyc8QeH6mUP4yTemEB7sT1F5LVeP\nT+Rn907l4VvHERbkx7tfnJRZ2aJHSU1B9Ctjh0aREBXErvRCvjZ9EO9vziQ1s4TQIH8evmU0E0fE\ndPlewQF+/OTuyWQWVJIypP0RTSMHRjDWqC386f3D2KwWDmWUeJuOms1IifPUOtLOXHB0VE2dk2PZ\nZQyJDyU6PACAX90/nYKSalKGRGKxWPD3s/Hdm8byu7cP8tePjvCbB2Z22L/Q6HRx6kwlidHBlzQB\nUJiDBAXRr1gtFhZNHcgbG4/z61f24HbDuKFRPPbNabganBd9v0CHnbFGv0VHbpk3jGOn93u/3QPM\nn5jUqjaSMiSSuIhAth4uYO6EpE47nFMzS2hyuZk86qsA5hly23pyXUpyFEtmDmbtrtMcyjjL7LGt\nZ00XlFSzakc2n+4+zbnaRiwWGDkgnEkjY1k4eQAO/69WF3Y2uXhpVRp5Z6upa2iirsFJXEQQ00bH\nMk3FES/LgJiGBAXR78wZl8CHWzNpcLq4Y+EIrpkygOjwQJ8tfTA8KZznfziXBqcLiwVsVgvBAa2/\nkdusVr59/Wj++80DvLwmnSe+PR1/v/aXfD9wwrPIYFdGa81IiWftrtMcPVXaKiikZ5fxu7cP4HZD\nSKAf8yYmkX+2mhPGUNrMgkoevmWcN/0XB/LYq4sJdNgJDrATFRpAbvE5sgureH9zJtNGx/G9m8Zi\ntbbf7OZ2u2lyuXtksIHb7ZbZ331IgoLodwIddv7P/dOxWi1EhQX02jMDL7BKhhocybXTBvLp3lxW\nbs3kzmtGnpem0enicEYJMeEBrZqfOjIoPoSQQD+Onipr9WH65eF83G54ZPlEJiRH4mf3fFhXVjfw\n/PuH2XusiPRTpaQkR1FT5+TjbacIdNh4+ruzCAvyDNWtrmvk4ImzfLYvl73HivgwKpDb5rU/6/u1\n9ZrNB/NJiA4iOSGUEQMjmDM24bzaSGlVPXERHe+tcepMJX9ZeYRlc5K962d117bUAqpqGlkys+f2\nGq9vaGLLoXwmj4ohpg/3CGl0NnEyt4LRRnNiT5KOZtEvxUQE9lpAuBi3zx9OXGQgG3bnoE+XnXde\nny6jrqGJKaNiu/THbrVYvPNECko8e4s4m1wcOllCVJiD62YN8QYE8KxFde/iUViANz49gbPJxdpd\n2ZyrbeT6WUO8AQE8fSpXjU/k0bsmERcRyOrt2exvs1Q6QGVNA1+mFuDwt1FWVc+OtEJeW6/58V+3\ns2bHKfLPVrNySyY//ut2fvriDj7YktHuUNpGp4uXV6dztqKO1zdoThd2XLMrrazrcDl2gDOlNbyy\n9hjvfnGSrILKDtNdrDc2Huetz07w1Gv7yDtbfeELfMDtdvM/Hx/l2bcPklvc83mQoCBEL3L42Xjg\n+hQA/vvNA/z2tb1s3JtDWlYp248UsH73aQAmj+x6h/gYo88j7ZRn25LjOeXU1DuZPLL9wJKcEMa8\nSZ7mpA82Z7JxTw6RoQ6undb+0NbgAD8euW08/n5W/r76KAUlrT+Itqeewdnk5pa5w3jhR/P47Xdm\nctNVyTS53Ly/OZNf/H0XH28/RUOji8hQB6u3Z/OvdRqXq3VgWL39FHlnqxkxMBxnk5uXPj5KQ+P5\nH/xbDuXzv1/cwTNvHehw9vo7n52gybj/h1uz2k1T1+Bkd3ohG/bk4GzqeBZ8sz3HivgytYCIEH/K\nzzXw32/s79GA01WbD+WzVxczamA4STE939dje+KJJ3r8pr2ppqbhie5eGxzsoKamoQdzc2UwY7kv\npzJHhwcwKC6EqppGTuRWkJpZyo60M+w/fpbi8jrCQ/y5a9HILs1nAE+fwca9OditVmaOiWfD7hyy\nCipZPn8YQwZEtFvu4UlhbD2UT3p2GU0uN3cvGsmwpI47v8OD/YmJCGDX0SKOnS5n7oREbFYrbreb\nf6xJp77RxYPLxuDwsxEa5M/oIZEsnJyEv5+NAH87S2cN5oEbUrhqfCLp2aUczight7iaEQPCCXTY\nOV1Yxctr0okMdfCze6caa0eVUF3vZOJwT4B0ud38e3MG/96UgdsN5efqCfS3nzebXOdU8Panxxk9\nOIKY8ACOnipj7NAob80xM7+S1zdoXl2v2Z1exJGsUsqq6pk0MqbD2llJRR1/eO8QFiv87JtTGRwf\nyp5jRew6WsiY5KjzBgH4Sl7xOf688giB/jYeu2uyt++qO7/fwcGOX7d3XPoUhOgDU0bFMmVULBXn\n6tl3vJiqmkbCQ/yJCHYwJCEUm7Xrlfjo8ADiIwM5droMZ5OL/SeKCQ6wM3JQRIfXhAb5c+u8Yby+\n4TgDYoLbXciwrVljEjiRW8EX+/NYte0Ut88fzrHT5RSW1TJ7bPx5w12DAvy46aqhrY45/Gz8729M\n4U/vH2b/8WL2H/d8462qbaTJ5eb+JaMJdNj5+sLhHMsp44v9eZwtr8PhZ6W8uoGTuRXERwby4LIx\nPP/+YT7cmsmUUTHeZeCdTS7+vioViwXuWjSSuoYm/uuN/Xy0NZNH75rMkcwSXvgglQani6SYYKaO\niuVIVglfphYQHuLf7raxTS4X/7P6KDX1Tu5fOprE6GASo4MJ8Lfx4kdpfLAlk0fvnNSVH9UlaWhs\n4sVVaTQ6XTx041ifNY9KUBCiD4WHOLhmysALJ7yAMUOj+GJ/Hl/sz6Osqp7ZYxMuOBJowaQBNDS6\nGDc0qsNRRW19fcFwUjNKWLvzNFNGxbL5YB4A89ts59qZQIedH90xiW2pBew6WsjxnHLcwNUTEhk3\nLBrAMw/jxrH87p2DpGaWeK8dPTiCh28dT0igH9+4dhR/W5XGv9ZpHrtrEk0uN2t3ZpNTeI4Fkwcw\nON4zo7151vn7mzNYt+s0FouFH9w+3ju6a9G0gTz12j7W7MgmNNCPa6YOxG6z0uh0sSPtDJ/syKao\nvJapo2KZ22J9rxkp8Xy6L5e0rFKKyms77UBvVlpZh8ViuaiahcvtZr8u5qNtWeQVV7Nw8gCmqktb\nR6wzsvOayXZoAnOWu7+Xef/xYl74IJVAh53aeieP3DqOqSrOJ+VOP1XKs28fJCEqiOLyWuKjgnhy\nxYxuj4Ipq6rnRG45k0bEnDdMt8nlor7BhbPJRZPLTUSIv/c5breb5/99mEMZJYwYEE5O8TnqG5oI\nDrDz24e+GkV1MreCp17fB3hqKv9r+YTzJiMWldfy1Gv7qKxuwIKnQ97ldlNV04jd5llRd/n84edN\nENx+pIC/r07n+llDvPtxuNxuPt2Tw7AB4YxoMR+luq6Rx/+2k7oGJ0tmDmHZ7CEdDktudupMJS+v\nSSevuBqLBa4an8i9Xxt13nWy85oQopXRgyOwWKC23omf3cq4odE+e1ZKchQLJiV5t1NtO1HvYkWG\nOryLBrZls1oJCmi/xmOxWPjmdYrjL+/mZJ6nWWnc+GhuXjCCEL+vrhkxMJxpo+M4ll3GD5dPaHfi\nYFxEID++ezLrdmZztqKO0qo66hqaWDx9ENfNGNzhN/tpKo63Pj3Bl4fzuWXuUOw2K5sO5PH25ycJ\nCfTjt9+ZSagRnNZs94zy8rdbWb39FDvTznDnNSOYPCq23f4jt9vNPz85Rn5xNXPGJXDjnORemUQo\nQUGIfiAowI9hiWFk5FcyNjmq1fwAX/j6whGkZpZQVdvYZ/tPA0SFBfDkihk4XW5v801735q/d9NY\nXO7OJ9cNiAlmxbIxF/V8fz8bc8YlsnFvDgdOnCU5IZT3vsjAYoFztY2890UGD9yQwtmKWj7dl0t0\nmINf3T+dtbtOs3FPDn9eeYT4qCCumzGIOWMTWtUA0rJKySk6x4yUOB68yHxdCp8GBaXUOOAj4Dmt\n9Qstjg8A3miRdBjwU8AfeBLIMI5v1Fr/1pd5FKK/GDs0ioz8ylbLY/hKoMPO4/dOpbbe2efrKXWl\nw9VqtWDFN7Ok509KYuPeHDYdyMPtdlPf2MQD16ewcW8OX6YWcNX4BLYcKsDZ5OLWecMIDfLnjoUj\nmDshkbU7T7Pz6BleXadZt/M0v/jWNO//59pdnuHJS2cO8Um+O+KzoKCUCgb+BHzW9pzWOg9YYKSz\nA5uAVcBy4B2t9WO+ypcQ/dV1MwYTHR7AnF765n45Tg7sC0kxwYwaFEF6tmcy4qQRMVw1PoHEmCCe\nenUff199lNLKegbFhTCrxVIkidHBPHBDCrfNH8aHW7PYciifv68+yv9aPoHsM1WkZ5cxNjmy17dx\n9eXktXrgeiD/AunuB97XWp/zYV6E6PcCHXbmTki6qOGsomcsmORZkiM4wM59SxQWi4XhSeHMnzyA\nksp63MDXFw5vt+8gIsTBfdcpxiZHcjijhPW7TntrCUtm9W4tAXxYU9BaOwGnUupCSR8EFrd4P18p\ntQ7wAx7TWh/wURaFEKJHTBsdx/GccqaoWCJCvuqUvn3+MFIzShgUF9Jp57/VauE7N47liX/u5v3N\nmbhxMyQ+lDEdLNnuSz4fkqqUegI427JPocW52cB3tdb3G+9HA8O11muMcy9prcd3dn+ns8ltt/u2\nU00IIbrL2eTCarF0aS7IkYyz/Pyv23C54Sf3TmPu5K7P/+iGy3JI6jLg0+Y3WutjwDHj9Q6lVKxS\nyqa17nDlq7Kymm4/vL+PXe+IGcttxjKDOct9JZc5PszBfUtGcyKnnJFJIV0uRzfnKbR7vK+DwnTg\n7eY3SqmfADla67eMkUvFnQUEIYTob+ZNTLrkZcMvhS9HH00Ffg8kA41KqeV4Rhhlaa1XGskSgaIW\nl70JvKaU+p6RtxW+yp8QQojz+bKjeR/GsNNO0oxv8z4XWOirPAkhhOicjF0TQgjhJUFBCCGElwQF\nIYQQXhIUhBBCeElQEEII4SVBQQghhNcVv/OaEEKIniM1BSGEEF4SFIQQQnhJUBBCCOElQUEIIYSX\nBAUhhBBeEhSEEEJ49fV+Cn1GKfUcMAtwAz/UWu/p4yz5hFLqGWAunp/108Ae4DXABhQA39Ra1/dd\nDn1HKRUIHAGeBD6jn5dbKXUP8BPACfwKOEz/L3MI8CoQCTiAXwNngL/i+ds+rLX+ft/lsGcZ+8x8\nBDyntX5BKTWIdn7Gxu/C/we48Oxg+XJXn2HKmoJSaj4wUms9G8+eDc/3cZZ8Qim1EBhnlHMJ8Afg\nN8CftdZzgZPAA32YRV/7BVBqvO7X5VZKRQP/B7gaz46GN9PPy2y4H9Ba64XAcuCPeH7Pf6i1vgoI\nV0ot7cP89RilVDDwJzxfcJqd9zM20v0KuBbP9gU/UkpFdfU5pgwKwCLgQwCtdToQqZQK69ss+cQW\n4OvG63IgGM8vySrj2Md4fnH6HWO/7zHAGuPQAvp3ua8FPtVaV2mtC7TWD9H/ywxwFog2Xkfi+RIw\ntEXNvz+Vux64HshvcWwB5/+MZwJ7tNYVWutaYBtwVVcfYtagkAAUt3hfbBzrV7TWTVrrauPtCuAT\nILhFE0IRnt3v+qPfA//Z4n1/L3cyEKSUWqWU2qqUWkT/LzNa67eBwUqpk3i+BD0GlLVI0m/KrbV2\nGh/yLbX3M277+XZR/wdmDQptWfo6A76klLoZT1D4jzan+mW5lVL3ATu01lkdJOmP5bbg+cZ8G54m\nlX/Supz9scwope4FTmutRwDXAK+3SdIvy92Bjsp6Uf8HZg0K+bSuGSTh6aTpd5RS1wE/B5ZqrSuA\nc0YHLMAAWldF+4sbgJuVUjuBB4Ff0v/LXQhsN75NZgBVQFU/LzN4mkXWA2itDwGBQEyL8/213M3a\n+71u+/l2Uf8HZg0KG/B0SqGUmgLka62r+jZLPU8pFQ48CyzTWjd3uH4K3G68vh1Y1xd58yWt9Z1a\n6+la61nA3/GMPurv5d4AXKOUshqdziH0/zKDp3N1JoBSagieYJiulLraOH8b/bPczdr7Ge8Cpiul\nIozRWVcBW7t6Q9OukqqU+i9gHp4hW48Y3zL6FaXUQ8ATwPEWh7+F54MyAMgGvq21buz93PUOpdQT\nwCk83yZfpR+XWyn1XTzNhAD/F8/w4/5e5hDgH0A8nmHXv8QzJPVveL707tJa/2fHd7hyKKWm4ukr\nSwYagTzgHuAV2vyMlVLLgR/jGZb7J631G119jmmDghBCiPOZtflICCFEOyQoCCGE8JKgIIQQwkuC\nghBCCC8JCkIIIbwkKAjRh5RS9yul2s7CFaLPSFAQQgjhJfMUhOgCpdQPgDvwTJA6BjwDrAbWAhON\nZHdprfOUUjfgWbq4xvj3kHF8Jp5lnRvwrOZ5H55ZqLcBlXhWdc0GbtNayx+m6BNSUxDiApRSM4Bb\ngXnG3hTleJYoHgb801jLfhPwqFIqCM+M8duNNf7X4pldDJ7F2r6jtZ4PbMazRhPAWOAhYCowDpjS\nG+USoj2m3XlNiIuwABgBfKGUAs++FAOAEq31PiPNNjw7XY0CCrXWucbxTcD3lFIxQITW+giA1voP\n4OlTwLP2fY3xPg+I8H2RhGifBAUhLqweWKW19i49rpRKBva3SGPBs85M22aflsc7qpk727lGiD4h\nzUdCXNg2YKmx+BpKqYfxbFoSqZSabKS5Gs+eyMeBOKXUYOP4tcBOrXUJcFYpNd24x6PGfYS4rEhQ\nEOICtNZ7gT8Dm5RSX+JpTqrAs0rl/Uqpz/EsT/ycsTPWCuAdpdQmPFu//sK41TeBPyqlNuNZoVeG\noorLjow+EqIbjOajL7XWA/s6L0L0JKkpCCGE8JKaghBCCC+pKQghhPCSoCCEEMJLgoIQQggvCQpC\nCCG8JCgIIYTwkqAghBDC6/8HMeRyMfAxMRcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aDMlqGtnZ6EF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adapting or tuning for prose writing"
      ]
    },
    {
      "metadata": {
        "id": "KsMf807zZ6EG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the evaluate function above, every time a prediction is made the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. As we turn the temperature towards zero we are choosing only the most likely outputs.\n"
      ]
    },
    {
      "metadata": {
        "id": "-hkcqnIlZ6EI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see the effects of this by adjusting the temperature argument."
      ]
    },
    {
      "metadata": {
        "id": "cSwY7UOEZ6EK",
        "colab_type": "code",
        "outputId": "bd0e7ec0-fb63-493f-e2fa-ed8fcc56339f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate('u', 200, temperature=0.8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unt.\n",
            "\n",
            "GRAMIO:\n",
            "I not shoo to to begaint, stell thought\n",
            "And sshe pastens, Pipchood, and she she did matter remed too do me Richire te\n",
            "portruch have Hange ham the her well suret the off tere me he with af\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WIjNrZNSZ6ER",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lower temperatures are less varied, choosing only the more probable outputs:"
      ]
    },
    {
      "metadata": {
        "id": "KPt6AhnNZ6ET",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "print(evaluate('Th', 200, temperature=0.2))"
      ]
    },
    {
      "metadata": {
        "id": "80cSDcEXZ6EU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Higher temperatures more varied, choosing less probable outputs:"
      ]
    },
    {
      "metadata": {
        "id": "NXusqAsCZ6EV",
        "colab_type": "code",
        "outputId": "a2e6468f-3abf-4f5d-b5dc-34193a33186d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "cell_type": "code",
      "source": [
        "print(evaluate('how', 200, temperature=1.4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how for thal to, the\n",
            "Juener theiar: dorce: 'y.\n",
            "\n",
            "QUEN LE:\n",
            "Shat I sawn. It brod this 'to and the gutt indeer good\n",
            "While me noges, Kise,\n",
            "An icnighsors? faitier-won the motheis to sho,\n",
            "Boold's, your's befull\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LOkO2rwFZ6Eb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 1:\n",
        "\n",
        "Change the number of epochs to 1000. Calculate the time taken and loss."
      ]
    },
    {
      "metadata": {
        "id": "Hf0b5N3MZ6Ec",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 2:\n",
        "\n",
        "Change the print every to 50 and plot every to 20. Calculate the time taken and loss and plot the loss graph"
      ]
    },
    {
      "metadata": {
        "id": "QyRAncKu7st7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Advanced "
      ]
    },
    {
      "metadata": {
        "id": "5CRZeawx7sDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtQo0EAjhkPb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cP4uAYCVZ6Ee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good, But Not Challenging for me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGNb7P7fhpbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"ok\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yr11lFXshrFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KsLmGpqmhtlg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id =return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51cY5cmcKJWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}